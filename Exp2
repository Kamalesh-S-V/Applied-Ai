import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn import metrics
from sklearn.metrics import (
    confusion_matrix,
    ConfusionMatrixDisplay,
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    roc_curve,
    auc,
    roc_auc_score
)
df = pd.read_csv('heart.csv')
print(df.head())
print(df.shape)
print(df.dtypes)
print(df.isnull().sum())
X = df.drop(columns=['output']).values
y = df['output'].values

print(X)
print("X shape:", X.shape)
print(y)
print("y shape:", y.shape)
unique_values = np.unique(y)
counts = np.zeros_like(unique_values)

for i, value in enumerate(unique_values):
    counts[i] = np.count_nonzero(y == value)

for i, value in enumerate(unique_values):
    print(f"Class label: {value}, Count: {counts[i]}")
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=0
)

print(X_train)
print("X_train shape:", X_train.shape)
print(X_test)
print("X_test shape:", X_test.shape)
print(y_train)
print("y_train shape:", y_train.shape)
print(y_test)
print("y_test shape:", y_test.shape)
unique_values = np.unique(y_test)
counts = np.zeros_like(unique_values)

for i, value in enumerate(unique_values):
    counts[i] = np.count_nonzero(y_test == value)

for i, value in enumerate(unique_values):
    print(f"Class label: {value}, Count: {counts[i]}")
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
dt_model = DecisionTreeClassifier(random_state=40)
dt_model.fit(X_train, y_train)
preds = dt_model.predict(X_test)
cm = confusion_matrix(y_test, preds)
print("Confusion Matrix")
print(cm)

disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])
fig, ax = plt.subplots(figsize=(5, 5))
plt.title("Confusion Matrix")
disp.plot(ax=ax)
plt.show()
accuracy = accuracy_score(y_test, preds)
precision = precision_score(y_test, preds)
recall = recall_score(y_test, preds)
f1 = f1_score(y_test, preds)
roc_auc = roc_auc_score(y_test, preds)

print("Accuracy:", accuracy * 100)
print("Precision:", precision * 100)
print("Recall:", recall * 100)
print("F1 Score:", f1 * 100)
print("ROC AUC Score:", roc_auc)
fpr, tpr, thresholds = roc_curve(y_test, preds)
roc_auc_value = auc(fpr, tpr)

plt.figure()
plt.plot([0, 1], [0, 1], 'k--', label='No Skill')
plt.plot(fpr, tpr, label='AUC = {:.3f}'.format(roc_auc_value))
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='best')
plt.show()
